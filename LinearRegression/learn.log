样本特征只有一个称谓简单线性回归
假设我们找到了最佳拟合的直线方程
y=ax+b
则对每一个样本点x(i)
根据我们的直线方程，预测值为y^(i) = ax(i)+b
计算y^(i)同y(i)值得差距
目标找到 a和b 是的（y(i) -（ax(i)+b））2尽可能小

通过分析问题，确定问题的损失函数或者效用函数
通过最优化损失函数或者效用函数，获得机器学习的模型

典型的最小二乘法问题：最小化误差平方


回归算法的评价
分类准确度
均方误差 MSE
均方根误差 RMSE
平均绝对误差 MAE
R Squared



